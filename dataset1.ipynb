{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9daw35fqhLBE",
        "outputId": "ef669f2c-ab46-4b8f-fdda-0dc78fb963ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset 1 (Household Energy) is Ready! ---\n",
            "Total rows: 19735\n",
            "\n",
            "--- First 5 rows of Energy Data ---\n",
            "   home_energy_wh  outside_temp_C\n",
            "0              60        6.600000\n",
            "1              60        6.483333\n",
            "2              50        6.366667\n",
            "3              50        6.250000\n",
            "4              60        6.133333\n"
          ]
        }
      ],
      "source": [
        "# --- Step 2: First Dataset - Household Energy (19,000+ rows!) ---\n",
        "\n",
        "# 1. Import necessary libraries, pandas and numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2. URL for the Household Energy dataset (this is precise sensor data)\n",
        "url_energy = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\"\n",
        "\n",
        "# 3. Read the CSV file into a pandas DataFrame\n",
        "df_energy = pd.read_csv(url_energy)\n",
        "\n",
        "# 4. We will select the 'Appliances' (energy) and 'T_out' (outside temp) columns\n",
        "# These are both good 'numeric' features for our model\n",
        "df_energy_final = df_energy[['Appliances', 'T_out']]\n",
        "\n",
        "# 5. Rename the columns to be more understandable\n",
        "df_energy_final = df_energy_final.rename(columns={\n",
        "    'Appliances': 'home_energy_wh',\n",
        "    'T_out': 'outside_temp_C'\n",
        "})\n",
        "\n",
        "# 6. ---- CRITICAL: Check the size of the data ----\n",
        "print(\"--- Dataset 1 (Household Energy) is Ready! ---\")\n",
        "print(f\"Total rows: {len(df_energy_final)}\")\n",
        "\n",
        "# 7. Print the first 5 rows to see what the data looks like\n",
        "print(\"\\n--- First 5 rows of Energy Data ---\")\n",
        "print(df_energy_final.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Second Dataset - Vehicle MPG ---\n",
        "\n",
        "# 1. URL for the vehicle dataset (Auto MPG from UCI)\n",
        "url_mpg = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
        "\n",
        "# 2. This data file doesn't have a header, so we must provide the column names\n",
        "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
        "\n",
        "# 3. Read the CSV.\n",
        "# na_values=\"?\" tells pandas to treat \"?\" as a missing (NaN) value\n",
        "# delim_whitespace=True tells pandas the columns are separated by spaces, not commas\n",
        "df_mpg = pd.read_csv(url_mpg, names=column_names, na_values=\"?\", delim_whitespace=True)\n",
        "\n",
        "# 4. ---- Data Cleaning ----\n",
        "# The 'horsepower' column has 6 missing values.\n",
        "# We will fill these gaps with the average (mean) horsepower of all other cars.\n",
        "# This is a key part of your Week 1 task.\n",
        "df_mpg['horsepower'] = df_mpg['horsepower'].fillna(df_mpg['horsepower'].mean())\n",
        "\n",
        "# 5. For our project, we only need the 'mpg' (mileage) and 'weight' columns\n",
        "df_vehicle_final = df_mpg[['mpg', 'weight']]\n",
        "\n",
        "# 6. Print the total size of this dataset\n",
        "print(\"--- Dataset 2 (Vehicle MPG) is Cleaned and Ready! ---\")\n",
        "print(f\"Total rows: {len(df_vehicle_final)}\")\n",
        "\n",
        "# 7. Print the first 5 rows to see what it looks like\n",
        "print(\"\\n--- First 5 rows of Vehicle Data ---\")\n",
        "print(df_vehicle_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbkuHqtekwcs",
        "outputId": "95e437e0-027a-462f-8774-a8059f8dc81b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1189901708.py:12: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df_mpg = pd.read_csv(url_mpg, names=column_names, na_values=\"?\", delim_whitespace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset 2 (Vehicle MPG) is Cleaned and Ready! ---\n",
            "Total rows: 398\n",
            "\n",
            "--- First 5 rows of Vehicle Data ---\n",
            "    mpg  weight\n",
            "0  18.0  3504.0\n",
            "1  15.0  3693.0\n",
            "2  18.0  3436.0\n",
            "3  16.0  3433.0\n",
            "4  17.0  3449.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Combine Datasets and Pre-process ---\n",
        "\n",
        "# 1. Create a copy of the large energy dataset to work on\n",
        "df_final = df_energy_final.copy()\n",
        "\n",
        "# 2. Get the lists of possible vehicle 'mpg' and 'weight' values\n",
        "mpg_values = df_vehicle_final['mpg'].values\n",
        "weight_values = df_vehicle_final['weight'].values\n",
        "\n",
        "# 3. Get the total number of rows from our energy data (19735)\n",
        "num_rows = len(df_final)\n",
        "\n",
        "# 4. ---- Feature Engineering (Part 1) ----\n",
        "# Assign a random car (mpg, weight) to each of the 19,735 energy readings\n",
        "\n",
        "# Create a new 'vehicle_mpg' column\n",
        "df_final['vehicle_mpg'] = np.random.choice(mpg_values, size=num_rows)\n",
        "\n",
        "# Create a new 'vehicle_weight' column\n",
        "df_final['vehicle_weight'] = np.random.choice(weight_values, size=num_rows)\n",
        "\n",
        "# 5. ---- Feature Engineering (Part 2) ----\n",
        "# Create our Target Variable (the 'answer' we want the AI to predict)\n",
        "# We will call it 'total_carbon_impact'.\n",
        "\n",
        "# We will create it using a formula based on our features.\n",
        "# This ensures the data has a real, predictable pattern.\n",
        "# (Energy * 0.4) + (Weight/MPG * 0.05) - (Temp * 0.1)\n",
        "\n",
        "energy_impact = df_final['home_energy_wh'] * 0.4\n",
        "vehicle_impact = (df_final['vehicle_weight'] / df_final['vehicle_mpg']) * 0.05\n",
        "temp_impact = df_final['outside_temp_C'] * 0.1\n",
        "\n",
        "# Add a little bit of random \"noise\" to make the data realistic\n",
        "noise = np.random.normal(0, 5, size=num_rows)\n",
        "\n",
        "# Combine them to create the final target column\n",
        "df_final['total_carbon_impact'] = energy_impact + vehicle_impact - temp_impact + noise\n",
        "\n",
        "# 6. ---- Final Check ----\n",
        "# All columns are now precise, numeric, and ready for an AI model.\n",
        "print(\"--- Final Combined & Pre-processed Dataset is Ready! ---\")\n",
        "print(f\"Total rows: {len(df_final)}\")\n",
        "print(f\"Total columns: {len(df_final.columns)}\")\n",
        "\n",
        "print(\"\\n--- First 5 rows of the FINAL Dataset ---\")\n",
        "print(df_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqwjKUr3lCV3",
        "outputId": "58732fdd-38d1-481c-c442-5a668d5a1298"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Final Combined & Pre-processed Dataset is Ready! ---\n",
            "Total rows: 19735\n",
            "Total columns: 5\n",
            "\n",
            "--- First 5 rows of the FINAL Dataset ---\n",
            "   home_energy_wh  outside_temp_C  vehicle_mpg  vehicle_weight  \\\n",
            "0              60        6.600000         13.0          3365.0   \n",
            "1              60        6.483333         32.0          2933.0   \n",
            "2              50        6.366667         31.6          2525.0   \n",
            "3              50        6.250000         26.0          4425.0   \n",
            "4              60        6.133333         16.5          4190.0   \n",
            "\n",
            "   total_carbon_impact  \n",
            "0            27.147640  \n",
            "1            40.910267  \n",
            "2            15.723166  \n",
            "3            28.682310  \n",
            "4            39.263961  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Save and Download the Final Dataset ---\n",
        "\n",
        "# 1. Define the filename for our final dataset\n",
        "final_filename = 'final_carbon_footprint_dataset.csv'\n",
        "\n",
        "# 2. Save the final DataFrame (df_final) to this CSV file\n",
        "# index=False means we don't save the row numbers (0, 1, 2, etc.)\n",
        "df_final.to_csv(final_filename, index=False)\n",
        "\n",
        "print(f\"--- Successfully saved data to {final_filename} ---\")\n",
        "\n",
        "# 3. Import the 'files' tool from Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "# 4. Use the 'files' tool to download the CSV to your computer\n",
        "print(f\"--- Downloading {final_filename} to your computer... ---\")\n",
        "files.download(final_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "UoimG5G_mIpN",
        "outputId": "a3eaa821-e80e-4b81-aa83-55e752692eb7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Successfully saved data to final_carbon_footprint_dataset.csv ---\n",
            "--- Downloading final_carbon_footprint_dataset.csv to your computer... ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3a874995-dd7e-4229-830e-c00afa1d87e4\", \"final_carbon_footprint_dataset.csv\", 874419)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}